{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01_数字識別ＡＩ対決_CNN_vs_IIC.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1QPcB9vSjI0elFu6wkLRP8YaBd5OlM7kP","authorship_tag":"ABX9TyN0l0LZj5gmkpCuj7apguwF"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zWQOy4KYBSHM"},"source":["# ０　元ネタ：ここを参考に実装しました\n"," - CNNの実装：Pytorch 学習済みモデルで識別[MNIST]\n","  - https://qiita.com/TKC-tkc/items/3b41620ecb9b22901413\n"," - IICの実装：相互情報量の最大化による教師なし学習手法IICの登場！\n","  - https://ai-scholar.tech/articles/treatise/iic-ai-367\n"," - アプリ開発：Jupyter上でDashを使えるjupyter_dash\n","  - https://qiita.com/OgawaHideyuki/items/725f4ffd93ffb0d30b6c\n"," - dash-canvas-ocr：手書き入力部分は、こちらを参考にしました\n","  - https://github.com/plotly/dash-sample-apps/tree/master/apps/dash-canvas-ocr\n"," - トンネリング：【Argo Tunnel】StreamlitアプリをGoogleColabから秒で外部公開する\n","  - https://www.space-i.com/post-blog/googlecola%E4%B8%8A%E3%81%8B%E3%82%89streamlit%E3%82%A2%E3%83%97%E3%83%AA%E3%82%92-cloudflare%E7%B5%8C%E7%94%B1%E3%81%A7%E7%A7%92%E3%81%A7%E5%A4%96%E9%83%A8%E5%85%AC%E9%96%8B%E3%81%99%E3%82%8B/"]},{"cell_type":"markdown","metadata":{"id":"nnM4IDToAvOq"},"source":["# １　必要なライブラリのインストール"]},{"cell_type":"code","metadata":{"id":"WSFdUwLa379c"},"source":["!pip install jupyter_dash\n","!pip install dash_canvas dash-bootstrap-components"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7krgKXXdJFH5"},"source":["# ２　ライブラリのインポート"]},{"cell_type":"markdown","metadata":{"id":"s2AFRBWZBgrX"},"source":["## ディープラーニング関係"]},{"cell_type":"code","metadata":{"id":"HANmNotTBZWL"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as f\n","import torchvision\n","from torchvision import datasets, transforms\n","from PIL import Image, ImageOps\n","from torchsummary import summary"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PQ0zi5m6BRE1"},"source":["## Webアプリ関係"]},{"cell_type":"code","metadata":{"id":"KH-roLMk4Lao"},"source":["import base64\n","from io import BytesIO\n","import pickle\n","from jupyter_dash import JupyterDash \n","import numpy as np\n","import dash_html_components as html\n","import dash_core_components as dcc\n","import dash_table\n","from dash_canvas import DashCanvas\n","from dash_canvas.utils import array_to_data_url, parse_jsonstring\n","from dash.dependencies import Input, Output, State\n","from dash.exceptions import PreventUpdate\n","from dash_table.Format import Format, Scheme\n","import dash_bootstrap_components as dbc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OUsToulEIxAZ"},"source":["# ３　学習済みモデルのロード（読み込み）"]},{"cell_type":"markdown","metadata":{"id":"mX3wOwrjB0Bc"},"source":["## ＣＮＮ学習済みモデルのロード"]},{"cell_type":"code","metadata":{"id":"QrFDZ0jm2-ci"},"source":["# モデルの定義\n","class MyNet(nn.Module):\n","    def __init__(self):\n","        super(MyNet,self).__init__()\n","        self.conv1 = nn.Conv2d(1,32,3,1)\n","        self.conv2 = nn.Conv2d(32,64,3,1)\n","        self.pool = nn.MaxPool2d(2,2)\n","        self.dropout1 = nn.Dropout2d(0.25)\n","        self.dropout2 = nn.Dropout2d(0.5)\n","        self.fc1 = nn.Linear(12*12*64,128)\n","        self.fc2 = nn.Linear(128,10)\n","\n","    def forward(self,x):\n","        x = self.conv1(x)\n","        x = f.relu(x)\n","        x = self.conv2(x)\n","        x = f.relu(x)\n","        x = self.pool(x)\n","        x = self.dropout1(x)\n","        x = x.view(-1,12*12*64)\n","        x = self.fc1(x)\n","        x = f.relu(x)\n","        x = self.dropout2(x)\n","        x = self.fc2(x)\n","\n","        return f.log_softmax(x, dim=1)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model_cnn = 0\n","model_cnn = MyNet().to(device)\n","print(device)\n","print(model_cnn)\n","print(summary(model_cnn, (1, 28, 28)))\n","\n","# 学習モデルをロードする\n","PATH = \"/content/drive/MyDrive/0_HanPy41/0_Welcomeデモ/model_CNN.pt\"\n","model_cnn.load_state_dict(torch.load(PATH, map_location=lambda storage, loc: storage))\n","model_cnn = model_cnn.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bbB7pl1pDsUi"},"source":["## ＩＩＣ学習済モデルのロード（読み込み）"]},{"cell_type":"code","metadata":{"id":"Bj-7v-58lKxK"},"source":["# ディープラーニングモデル\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.nn.init as init\n","\n","def weight_init(m):\n","    \"\"\"重み初期化\"\"\"\n","    if isinstance(m, nn.Conv2d):\n","        init.xavier_normal_(m.weight.data)\n","        if m.bias is not None:\n","            init.normal_(m.bias.data)\n","    elif isinstance(m, nn.BatchNorm2d):\n","        init.normal_(m.weight.data, mean=1, std=0.02)\n","        init.constant_(m.bias.data, 0)\n","    elif isinstance(m, nn.Linear):\n","        init.kaiming_normal_(m.weight.data)\n","        if m.bias is not None:\n","            init.normal_(m.bias.data)\n","\n","OVER_CLUSTRING_Rate = 10  # 多めに分類するoverclsuteringも用意する\n","\n","class NetIIC(nn.Module):\n","    def __init__(self):\n","        super(NetIIC, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(1, 128, 5, 2, bias=False)\n","        self.bn1 = nn.BatchNorm2d(128)\n","        self.conv2 = nn.Conv2d(128, 128, 5, 1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(128)\n","        self.conv3 = nn.Conv2d(128, 128, 5, 1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        self.conv4 = nn.Conv2d(128, 256, 4, 1, bias=False)\n","        self.bn4 = nn.BatchNorm2d(256)\n","\n","        # 0-9に対応すると期待したい10種類のクラス\n","        self.fc = nn.Linear(256, 10)\n","\n","        # overclustering\n","        # 実際の想定よりも多めにクラスタリングさせることで、ネットワークで微細な変化を捉えられるようにする\n","        self.fc_overclustering = nn.Linear(256, 10*OVER_CLUSTRING_Rate)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        x = F.relu(self.bn4(self.conv4(x)))\n","        x_prefinal = x.view(x.size(0), -1)\n","        y = F.softmax(self.fc(x_prefinal), dim=1)\n","\n","        y_overclustering = F.softmax(self.fc_overclustering(\n","            x_prefinal), dim=1)  # overclustering\n","\n","        return y, y_overclustering\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# モデル\n","model_IIC = NetIIC()\n","model_IIC.apply(weight_init)\n","model_IIC.to(device)\n","\n","# 学習モデルをロードする\n","PATH = \"/content/drive/MyDrive/0_HanPy41/0_Welcomeデモ/model_IIC.pt\"\n","model_IIC.load_state_dict(torch.load(PATH, map_location=lambda storage, loc: storage))\n","model_IIC = model_IIC.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TuyB9RumImHi"},"source":["# ４　Ｗｅｂアプリの実装"]},{"cell_type":"markdown","metadata":{"id":"brGfaYe6FEwp"},"source":["## 入力イメージの補正関数"]},{"cell_type":"code","metadata":{"id":"PUQ0FBbiCmfu"},"source":["def get_box(image):\n","    imgArray = np.asarray(image)\n","\n","    lst_x, lst_y = [], []\n","    for i, row in enumerate(imgArray):\n","        if row.max() > 150:\n","            lst_y.append(i)\n","        for j, pix in enumerate(row):\n","            if pix > 150:\n","                lst_x.append(j)\n","\n","    upper = np.array(lst_y).min()\n","    bottom = np.array(lst_y).max()\n","    left = np.array(lst_x).min()\n","    right = np.array(lst_x).max()\n","\n","    return (left, upper, right + 1, bottom + 1), bottom - upper, right - left\n","\n","def treat_image(image):\n","    box, h, w = get_box(image)\n","    im_crop = image.crop(box)\n","    im_base = im_crop.resize((int(w/h*160), 160))\n","    im_mask = Image.new(\"L\", (200, 200), 0)\n","    im_mask.paste(im_base, (100 - int(w/h*80), 20))\n","\n","    return im_mask"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DZYivJCJFZ-f"},"source":["## Ｗｅｂアプリの本体"]},{"cell_type":"code","metadata":{"cellView":"code","id":"fk34jWZl4LSg"},"source":["app = JupyterDash(__name__, \n","                external_stylesheets=[dbc.themes.JOURNAL],\n","                meta_tags=[{\n","                    'name': 'viewport',\n","                    'content': 'width=device-width, initial-scale=1.0',\n","                    }]\n","                )\n","\n","canvas_width = 224\n","canvas_height = 224\n","\n","dic_IIC = {0:\"6\", 1:\"2\", 2:\"7\", 3:\"1\", 4:\"4\", 5:\"5\", 6:\"3\", 7:\"9\", 8:\"0\", 9:\"8\"}\n","\n","app.layout = dbc.Container([\n","    # １行目\n","    dbc.Row([\n","        dbc.Col([\n","            html.H4(\"数字識別ＡＩ対決\")\n","        ], width=\"auto\"),\n","    ], justify = 'center', style = {'margin':'10px 0px 0px 0px'}),\n","    # ２行目\n","    dbc.Row([\n","        dbc.Col([\n","            dash_table.DataTable(\n","                id='id-table',\n","                style_cell={'textAlign':'center', 'fontSize':18, 'width':70, 'fontWeight':'bold'},\n","                columns=[{\"name\":\"学習モデル\",\"id\":\"モデル\"}, \n","                        {\"name\":\" CNN \",\"id\":\"ＣＮＮ\"},\n","                        {\"name\":\" IIC \",\"id\":\"ＩＩＣ\"},\n","                        ],\n","                data=[{\"モデル\":\"識別結果\",\"ＣＮＮ\":\"\",\"ＩＩＣ\":\"\"}],\n","                # fill_width=True,\n","            ) \n","        ], width=\"auto\"),\n","    ], justify = 'center', style = {'margin':'20px 0px 0px 0px'}),\n","    # ３行目\n","    dbc.Row([\n","        dbc.Col([\n","            # Canvas\n","            DashCanvas(\n","                id=\"id-canvas\",\n","                lineWidth=16,\n","                width=canvas_width,\n","                height=canvas_height,\n","                hide_buttons=[\n","                    \"zoom\",\n","                    \"pan\",\n","                    \"line\",\n","                    \"pencil\",\n","                    \"rectangle\",\n","                    \"select\",\n","                ],\n","                lineColor=\"black\",\n","                goButtonTitle=\"　識　　別　\",\n","            ),\n","        ], width=\"auto\"),\n","    ], justify = 'center', style = {'margin':'20px 0px 0px 0px'}),\n","])\n","\n","\n","@app.callback(\n","    Output(\"id-table\", \"data\"), \n","    [Input(\"id-canvas\", \"json_data\")],\n",")\n","def update_data(string):\n","    if string:\n","        try:\n","            mask = parse_jsonstring(string, shape=(canvas_height, canvas_width))\n","        except:\n","            return \"Out of Bounding Box, click clear button and try again\"\n","        mask = (~mask.astype(bool)).astype(int)\n","\n","        image_string = array_to_data_url((255 * mask).astype(np.uint8))\n","        image = Image.open(BytesIO(base64.b64decode(image_string[22:])))\n","        temp  = image\n","        in_image = image.convert('L').resize((28,28))\n","\n","        in_data = []\n","        for i in range(28):\n","            for j in range(28):\n","                temp = abs(in_image.getpixel((j,i)) - 255)/255\n","                if temp < 0.4:\n","                    temp = 0\n","                elif temp < 0.5:\n","                    temp *= 1.2 \n","                in_data.append(temp)\n","\n","        image = ImageOps.invert(image)\n","        image = treat_image(image) # 入力イメージを整形\n","        in_image = image.resize((28,28))\n","        # データの前処理の定義(モデル生成の際と同じ平均値と標準偏差で正規化する)\n","        transform = transforms.Compose([\n","                                        transforms.ToTensor(),\n","                                        transforms.Normalize((0.1307,), (0.3081,))\n","                                        ])\n","\n","        # 元のモデルに合わせて次元を追加\n","        image = transform(in_image).unsqueeze(0)\n","\n","        # IIC\n","        img_in = image.to(device)\n","        outputs, _ = model_IIC(img_in)\n","        out = outputs.argmax(dim=1).cpu()\n","        v_IIC = dic_IIC[int(out)]\n","\n","        # 予測を実施 CNN\n","        output = model_cnn(image.to(device))\n","        _, prediction = torch.max(output, 1)\n","        # 結果を出力\n","        v_CNN = str(prediction[0].item())\n","        # 識別結果の出力\n","        v_data=[{\"モデル\":\"識別結果\",\"ＣＮＮ\":v_CNN, \"ＩＩＣ\":v_IIC}, ]\n","        return v_data\n","    else:\n","        raise PreventUpdate"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EN05sq-DGEyy"},"source":["# ５　Ｗｅｂアプリをローカル環境で実行"]},{"cell_type":"code","metadata":{"id":"ufBjR03fF54w"},"source":["# app.run_server(mode=\"inline\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KPv2fSi7GoGr"},"source":["# ６　Ｗｅｂアプリのデプロイ"]},{"cell_type":"markdown","metadata":{"id":"3ncA3AcVHR-U"},"source":["## externalモードでWebアプリを起動"]},{"cell_type":"code","metadata":{"id":"arDgbcB6zk7g"},"source":["app.run_server(mode='external', host=\"localhost\", port=8030, debug=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q-2o5oFdHqgE"},"source":["## トンネリングで公開ＵＲＬを発行"]},{"cell_type":"code","metadata":{"id":"IOxMFCHyrV2P"},"source":["# cloudflaredのインストール　＆　localhostの8030ポートのトンネリングした公開URLを発行\n","!wget https://bin.equinox.io/c/VdrWdbjqyF/cloudflared-stable-linux-amd64.deb\n","!dpkg -i cloudflared-stable-linux-amd64.deb\n","!cloudflared tunnel --url localhost:8030"],"execution_count":null,"outputs":[]}]}